{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science – Practical Natural Language Processing (NLP)\n",
    "*COMP 5360 / MATH 4100, University of Utah, http://datasciencecourse.net/* \n",
    "\n",
    "In this lecture, we'll do some practical NLP following up on last week's theoretical lecture. We will do some basic text processing followed by a sentiment analysis for movie reviews. For this purpose, we'll introduce  the [Natural Language Toolkit (NLTK)](http://www.nltk.org/), a Python library for  Natural Language Processing. \n",
    "\n",
    "We won't cover NLTK or NLP extensively here – this lecture is meant to give you a few pointers if you want to use NLP in the future, e.g., for your project.\n",
    "\n",
    "Also, there is a well-regarded alternative to NLTK: [Spacy](https://spacy.io/). If you're planning to use a lot of NLP in your project, that might be worth checking out. \n",
    "\n",
    "**Reading:** \n",
    "\n",
    "[S. Bird, E. Klein, and E. Loper, *Natural Language Processing with Python – Analyzing Text with the Natural Language Toolkit*](http://www.nltk.org/book/). \n",
    "\n",
    "\n",
    "[C. Manning and H. Schütze, *Foundations of Statistical Natural Language Processing* (1999).](http://nlp.stanford.edu/fsnlp/)\n",
    "\n",
    "[D. Jurafsky and J. H. Martin, *Speech and Language Processing* (2016).](https://web.stanford.edu/~jurafsky/slp3/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**In a prior lecture,** guest lecturer Vivek Srikumar gave a nice overview of Natural Language Processing (NLP). He gave several examples of NLP tasks: \n",
    "* Part of speech tagging (what are the nouns, verbs, adjectives, prepositions).\n",
    "+ Information Extraction\n",
    "+ Sentiment Analysis (determine the attitude of text, e.g., is it positive or negative).\n",
    "+ Semantic Parsing (translate natural language into a formal meaning representation).\n",
    "\n",
    "One of the major takeaways from his talk is that the current state-of-the-art for many NLP tasks is to find a good way to represent the text (\"extract features\") and then to use machine learning / statistics tools, such as classification or clustering. \n",
    "\n",
    "Our goal today is to use NLTK + scikit-learn to do some basic NLP tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install datasets and models\n",
    "\n",
    "To use NLTK, you must first download and install the datasets and models. Run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /Users/alex/nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics of NLTK\n",
    "\n",
    "We have downloaded a set of text corpora above. Here is a list of these texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first 20 words of text1 – Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[',\n",
       " 'Moby',\n",
       " 'Dick',\n",
       " 'by',\n",
       " 'Herman',\n",
       " 'Melville',\n",
       " '1851',\n",
       " ']',\n",
       " 'ETYMOLOGY',\n",
       " '.',\n",
       " '(',\n",
       " 'Supplied',\n",
       " 'by',\n",
       " 'a',\n",
       " 'Late',\n",
       " 'Consumptive',\n",
       " 'Usher',\n",
       " 'to',\n",
       " 'a',\n",
       " 'Grammar']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Statistics\n",
    "\n",
    "We can check the length of a text. The text of Moby Dick is 26,0819 words, whereas Monty Python and the Holy Grail has 16,967 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260819"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16967"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check for the frequency of a word. The word \"swallow\" appears 10 times in Monty Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text6.count(\"swallow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to know the context in which \"swallow\" appears in the text\n",
    "\n",
    "\"You shall know a word by the company it keeps.\" – John Firth\n",
    "\n",
    "Use the [`concordance`](http://www.nltk.org/api/nltk.html#nltk.text.Text.concordance) function to print out the words just before and after all occurrences of the word \"swallow\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 10 of 10 matches:\n",
      " is a temperate zone . ARTHUR : The swallow may fly south with the sun or the h\n",
      "be carried . SOLDIER # 1 : What ? A swallow carrying a coconut ? ARTHUR : It co\n",
      "o maintain air - speed velocity , a swallow needs to beat its wings forty - thr\n",
      ": It could be carried by an African swallow ! SOLDIER # 1 : Oh , yeah , an Afri\n",
      "OLDIER # 1 : Oh , yeah , an African swallow maybe , but not a European swallow \n",
      " swallow maybe , but not a European swallow . That ' s my point . SOLDIER # 2 :\n",
      " and Sir Bedevere , not more than a swallow ' s flight away , had discovered so\n",
      "omething . Oh , that ' s an unladen swallow ' s flight , obviously . I mean , t\n",
      " air - speed velocity of an unladen swallow ? ARTHUR : What do you mean ? An Af\n",
      "o you mean ? An African or European swallow ? BRIDGEKEEPER : Huh ? I -- I don '\n"
     ]
    }
   ],
   "source": [
    "text6.concordance(\"swallow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words that occur with notable frequencey are \"fly\" or \"flight\", \"unladen\", \"air\", \"African\", \"European\". We can learn about what a swallow can do or properties of a swallow by this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we look for Ishmael in Moby Dick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 20 of 20 matches:\n",
      "SONG . CHAPTER 1 Loomings . Call me Ishmael . Some years ago -- never mind how \n",
      "ED STATES . \" WHALING VOYAGE BY ONE ISHMAEL . \" BLOODY BATTLE IN AFFGHANISTAN .\n",
      "f silver ,-- So , wherever you go , Ishmael , said I to myself , as I stood in \n",
      "de to lodge for the night , my dear Ishmael , be sure to inquire the price , an\n",
      "nkling glasses within . But go on , Ishmael , said I at last ; don ' t you hear\n",
      "g and teeth - gnashing there . Ha , Ishmael , muttered I , backing out , Wretch\n",
      "emen who had gone before me . Yes , Ishmael , the same fate may be thine . But \n",
      " ? thought I . Do you suppose now , Ishmael , that the magnanimous God of heave\n",
      "l , which , if left to myself , I , Ishmael , should infallibly light upon , fo\n",
      " Bildad . Now then , my young man , Ishmael ' s thy name , didn ' t ye say ? We\n",
      "say ? Well then , down ye go here , Ishmael , for the three hundredth lay .\" \" \n",
      "why don ' t you speak ? It ' s I -- Ishmael .\" But all remained still as before\n",
      "l fear ! CHAPTER 41 Moby Dick . I , Ishmael , was one of that crew ; my shouts \n",
      "lain , would be to dive deeper than Ishmael can go . The subterranean miner tha\n",
      "oul ; thou surrenderest to a hypo , Ishmael . Tell me , why this strong young c\n",
      " snows of prairies ; all these , to Ishmael , are as the shaking of that buffal\n",
      "ubtle meanings , how may unlettered Ishmael hope to read the awful Chaldee of t\n",
      "onditional skeleton . But how now , Ishmael ? How is it , that you , a mere oar\n",
      " for exhibition ? Explain thyself , Ishmael . Can you land a full - grown whale\n",
      "le witness have you hitherto been , Ishmael ; but have a care how you seize the\n"
     ]
    }
   ],
   "source": [
    "text1.concordance(\"Ishmael\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see a lot of \"I\"s. We could probably infer that it's a person based on that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what other words frequently appear in the same context using the  [`similar`](http://www.nltk.org/api/nltk.html#nltk.text.Text.similar) function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plover\n"
     ]
    }
   ],
   "source": [
    "text6.similar(\"swallow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unladen\n"
     ]
    }
   ],
   "source": [
    "text6.similar(\"african\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "castle lord what horse robinson scratch draw bristol model god grail\n",
      "sniff sacrifice bride test mistake\n"
     ]
    }
   ],
   "source": [
    "text6.similar(\"coconut\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that 'african' and 'unladen' both appeared in the text with the same word just before and just after. To see what the phrase is, we can use the [`common_contexts`](http://www.nltk.org/api/nltk.html#nltk.text.Text.concordance) function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an_swallow\n"
     ]
    }
   ],
   "source": [
    "text6.common_contexts([\"African\", \"unladen\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that both \"an unladen swallow\" and \"an african swallow\" appear in the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 2 of 2 matches:\n",
      "overed something . Oh , that ' s an unladen swallow ' s flight , obviously . I \n",
      "t is the air - speed velocity of an unladen swallow ? ARTHUR : What do you mean\n",
      "\n",
      "Displaying 4 of 4 matches:\n",
      "IER # 2 : It could be carried by an African swallow ! SOLDIER # 1 : Oh , yeah ,\n",
      "llow ! SOLDIER # 1 : Oh , yeah , an African swallow maybe , but not a European \n",
      "LDIER # 1 : But then of course a -- African swallows are non - migratory . SOLD\n",
      "ow ? ARTHUR : What do you mean ? An African or European swallow ? BRIDGEKEEPER \n"
     ]
    }
   ],
   "source": [
    "text6.concordance(\"unladen\")\n",
    "print()\n",
    "text6.concordance(\"african\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispersion plot\n",
    "\n",
    "`text4` is the Inaugural Address Corpus which includes inaugural addresses going back to 1789. \n",
    "We can use a dispersion plot to see where in a text certain words appear, and hence how the language of the address has changed over time. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text4.dispersion_plot([\"citizens\", \"democracy\", \"freedom\", \"duty\", \"America\", \"nation\", \"God\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring texts using statistics\n",
    "\n",
    "We'll explore a text by counting the frequency of different words.\n",
    "\n",
    "The total number of words (\"outcomes\") in Moby Dick is 260,819 and the number of different words is 19,317. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 19317 samples and 260819 outcomes>\n",
      "\n",
      " [(',', 18713), ('the', 13721), ('.', 6862), ('of', 6536), ('and', 6024), ('a', 4569), ('to', 4542), (';', 4072), ('in', 3916), ('that', 2982), (\"'\", 2684), ('-', 2552), ('his', 2459), ('it', 2209), ('I', 2124), ('s', 1739), ('is', 1695), ('he', 1661), ('with', 1659), ('was', 1632), ('as', 1620), ('\"', 1478), ('all', 1462), ('for', 1414), ('this', 1280), ('!', 1269), ('at', 1231), ('by', 1137), ('but', 1113), ('not', 1103), ('--', 1070), ('him', 1058), ('from', 1052), ('be', 1030), ('on', 1005), ('so', 918), ('whale', 906), ('one', 889), ('you', 841), ('had', 767), ('have', 760), ('there', 715), ('But', 705), ('or', 697), ('were', 680), ('now', 646), ('which', 640), ('?', 637), ('me', 627), ('like', 624)]\n",
      "\n",
      " 906\n"
     ]
    }
   ],
   "source": [
    "frequency_dist = FreqDist(text1)\n",
    "print(frequency_dist)\n",
    "\n",
    "# find 50 most common words\n",
    "print('\\n',frequency_dist.most_common(50))\n",
    "\n",
    "# not suprisingly, whale occurs quite frequently (906 times!)\n",
    "print('\\n', frequency_dist['whale'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find all the words in Moby Dick with more than 15 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apprehensiveness',\n",
       " 'characteristically',\n",
       " 'irresistibleness',\n",
       " 'comprehensiveness',\n",
       " 'superstitiousness',\n",
       " 'indispensableness',\n",
       " 'supernaturalness',\n",
       " 'physiognomically',\n",
       " 'undiscriminating',\n",
       " 'subterraneousness',\n",
       " 'uncomfortableness',\n",
       " 'circumnavigating',\n",
       " 'cannibalistically',\n",
       " 'hermaphroditical',\n",
       " 'responsibilities',\n",
       " 'uninterpenetratingly',\n",
       " 'circumnavigation',\n",
       " 'uncompromisedness',\n",
       " 'physiognomically',\n",
       " 'indiscriminately',\n",
       " 'preternaturalness',\n",
       " 'circumnavigations',\n",
       " 'simultaneousness',\n",
       " 'circumnavigation']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = set(text1)\n",
    "long_words = [w.lower() for w in unique_words if len(w) > 15]\n",
    "long_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword Removal\n",
    "\n",
    "Sometimes, it is useful to ignore frequently used words, to concentrate on the meaning of the remaining words. These are referred to as *stopwords*. Examples are \"the\", \"was\", \"is\", etc. \n",
    "\n",
    "NLTK comes with a stopword corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the task, these stopwords are important modifiers, or superfluous content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Frequent Words\n",
    "Find the most frequently used words in Moby Dick that are not stopwords and not punctuation. Hint: [`str.isalpha()`](https://docs.python.org/3/library/stdtypes.html#str.isalpha) could be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords in different corpora\n",
    "Is there a difference between the frequency in which stopwords appear in the different texts? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5862954769399469\n",
      "2 0.5285429733853195\n",
      "3 0.5496381020462872\n",
      "4 0.5228599855902837\n",
      "5 0.7097756054210176\n",
      "6 0.7195732893263393\n",
      "7 0.697187015773372\n",
      "8 0.8255598931580028\n",
      "9 0.5608339473798275\n"
     ]
    }
   ],
   "source": [
    "def content_fraction(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return len(content) / len(text)\n",
    "\n",
    "for i,t in enumerate([text1,text2,text3,text4,text5,text6,text7,text8,text9]):\n",
    "    print(i+1,content_fraction(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, \"text8: Personals Corpus\" has the most content. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations\n",
    "A *collocation* is a sequence of words that occur together unusually often, we can retreive these using the [`collocations()`](http://www.nltk.org/api/nltk.html#nltk.text.Text.collocations) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sperm Whale; Moby Dick; White Whale; old man; Captain Ahab; sperm\n",
      "whale; Right Whale; Captain Peleg; New Bedford; Cape Horn; cried Ahab;\n",
      "years ago; lower jaw; never mind; Father Mapple; cried Stubb; chief\n",
      "mate; white whale; ivory leg; one hand\n"
     ]
    }
   ],
   "source": [
    "text1.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis for movie reviews\n",
    "We ask the simple question: Is the attitude of a movie review positive or negative? \n",
    "\n",
    "How can we approach this question?\n",
    "\n",
    "Our data is a corpus consisting of 2000 movie reviews together with the user's sentiment polarity (positive or negative). More information about this dataset is available [from this website](https://www.cs.cornell.edu/people/pabo/movie-review-data/).\n",
    "\n",
    "Our goal is to predict the sentiment polarity from just the review. \n",
    "\n",
    "Of course, this is something that we can do very easily: \n",
    "1. That movie was terrible. -> negative\n",
    "+ That movie was great! -> positive\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import movie_reviews as reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datset contains 1000 positive and 1000 negative movie reviews. \n",
    "\n",
    "The paths to / IDs for the individual reviews are accessible via the fileids() call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg/cv000_29416.txt',\n",
       " 'neg/cv001_19502.txt',\n",
       " 'neg/cv002_17424.txt',\n",
       " 'neg/cv003_12683.txt',\n",
       " 'neg/cv004_12641.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.fileids()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the positives or negatives explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos/cv000_29590.txt',\n",
       " 'pos/cv001_18431.txt',\n",
       " 'pos/cv002_15918.txt',\n",
       " 'pos/cv003_11664.txt',\n",
       " 'pos/cv004_11636.txt']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.fileids('pos')[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are in fact 1000 positive and 1000 negative reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "1000 1000\n"
     ]
    }
   ],
   "source": [
    "num_reviews = len(reviews.fileids())\n",
    "print(num_reviews)\n",
    "print(len(reviews.fileids('pos')),len(reviews.fileids('neg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the review for the third movie. Its a negative review for [The Mod Squad](https://www.rottentomatoes.com/m/mod_squad/), which has a \"rotten\" rating on rotten tomatoes. \n",
    "\n",
    "![Mod Squad at Rotten Tomatoes](mod_squad.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg/cv002_17424.txt\n",
      "\n",
      " it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch . \n",
      "based on the late 1960's television show by the same name , the mod squad tells the tale of three reformed criminals under the employ of the police to go undercover . \n",
      "however , things go wrong as evidence gets stolen and they are immediately under suspicion . \n",
      "of course , the ads make it seem like so much more . \n",
      "quick cuts , cool music , claire dane's nice hair and cute outfits , car chases , stuff blowing up , and the like . \n",
      "sounds like a cool movie , does it not ? \n",
      "after the first fifteen minutes , it quickly becomes apparent that it is not . \n",
      "the mod squad is certainly a slick looking production , complete with nice hair and costumes , but that simply isn't enough . \n",
      "the film is best described as a cross between an hour-long cop show and a music video , both stretched out into the span of an hour and a half . \n",
      "and with it comes every single clich ? . \n",
      "it doesn't really matter that the film is based on a television show , as most of the plot elements have been recycled from everything we've already seen . \n",
      "the characters and acting is nothing spectacular , sometimes even bordering on wooden . \n",
      "claire danes and omar epps deliver their lines as if they are bored , which really transfers onto the audience . \n",
      "the only one to escape relatively unscathed is giovanni ribisi , who plays the resident crazy man , ultimately being the only thing worth watching . \n",
      "unfortunately , even he's not enough to save this convoluted mess , as all the characters don't do much apart from occupying screen time . \n",
      "with the young cast , cool clothes , nice hair , and hip soundtrack , it appears that the film is geared towards the teenage mindset . \n",
      "despite an american 'r' rating ( which the content does not justify ) , the film is way too juvenile for the older mindset . \n",
      "information on the characters is literally spoon-fed to the audience ( would it be that hard to show us instead of telling us ? ) , dialogue is poorly written , and the plot is extremely predictable . \n",
      "the way the film progresses , you likely won't even care if the heroes are in any jeopardy , because you'll know they aren't . \n",
      "basing the show on a 1960's television show that nobody remembers is of questionable wisdom , especially when one considers the target audience and the fact that the number of memorable films based on television shows can be counted on one hand ( even one that's missing a finger or two ) . \n",
      "the number of times that i checked my watch ( six ) is a clear indication that this film is not one of them . \n",
      "it is clear that the film is nothing more than an attempt to cash in on the teenage spending dollar , judging from the rash of really awful teen-flicks that we've been seeing as of late . \n",
      "avoid this film at all costs . \n",
      "\n",
      "\n",
      " The Category: ['neg']\n",
      "\n",
      " Individual Words: ['it', 'is', 'movies', 'like', 'these', 'that', 'make', ...]\n"
     ]
    }
   ],
   "source": [
    "# the name of the file \n",
    "fid = reviews.fileids()[2]\n",
    "print(fid)\n",
    "\n",
    "print('\\n', reviews.raw(fid))\n",
    "\n",
    "\n",
    "print('\\n', \"The Category:\", reviews.categories(fid) )\n",
    "\n",
    "print('\\n', \"Individual Words:\",reviews.words(fid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some sentences that indicate that this is a negative review:\n",
    "\n",
    " * \"it is movies like these that make a jaded movie viewer thankful for the invention of the timex indiglo watch\"\n",
    " * \"sounds like a cool movie , does it not ? after the first fifteen minutes , it quickly becomes apparent that it is not .\" \n",
    " * \"nothing spectacular\"\n",
    " * \"avoid this film at all costs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Custom Algorithm\n",
    "We'll build a sentiment classifier using methods we already know to predicts the label ['neg', 'pos'] from the review text\n",
    "\n",
    "`reviews.categories(file_id)` returns the label ['neg', 'pos'] for that movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [reviews.categories(fid) for fid in reviews.fileids()]\n",
    "labels = {'pos':1, 'neg':0}\n",
    "# create the labels - 1 for positive, 0 for negative\n",
    "y = [labels[x[0]] for x in categories]\n",
    "y[0], y[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we collect all words into a nested array datastructure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_words = [list(reviews.words(fid)) for fid in reviews.fileids()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is', 'movies', 'like', 'these', 'that', 'make', 'a', 'jaded', 'movie']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 10 words of the third document - mod squad\n",
    "doc_words[2][1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get all of the words in the reviews and make a FreqDist, pick the most common 2000 words and remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('film', 9517),\n",
       " ('one', 5852),\n",
       " ('movie', 5771),\n",
       " ('like', 3690),\n",
       " ('even', 2565),\n",
       " ('good', 2411),\n",
       " ('time', 2411),\n",
       " ('story', 2169),\n",
       " ('would', 2109),\n",
       " ('much', 2049),\n",
       " ('character', 2020),\n",
       " ('also', 1967),\n",
       " ('get', 1949),\n",
       " ('two', 1911),\n",
       " ('well', 1906),\n",
       " ('characters', 1859),\n",
       " ('first', 1836),\n",
       " ('see', 1749),\n",
       " ('way', 1693),\n",
       " ('make', 1642),\n",
       " ('life', 1586),\n",
       " ('really', 1558),\n",
       " ('films', 1536),\n",
       " ('plot', 1513),\n",
       " ('little', 1501),\n",
       " ('people', 1455),\n",
       " ('could', 1427),\n",
       " ('scene', 1397),\n",
       " ('man', 1396),\n",
       " ('bad', 1395),\n",
       " ('never', 1374),\n",
       " ('best', 1333),\n",
       " ('new', 1292),\n",
       " ('scenes', 1274),\n",
       " ('many', 1268),\n",
       " ('director', 1237),\n",
       " ('know', 1217),\n",
       " ('movies', 1206),\n",
       " ('action', 1172),\n",
       " ('great', 1148),\n",
       " ('another', 1121),\n",
       " ('love', 1119),\n",
       " ('go', 1113),\n",
       " ('made', 1084),\n",
       " ('us', 1073),\n",
       " ('big', 1064),\n",
       " ('end', 1062),\n",
       " ('something', 1061),\n",
       " ('back', 1060),\n",
       " ('still', 1047)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the 2000 most common words in lowercase\n",
    "most_common = nltk.FreqDist(w.lower() for w in reviews.words()).most_common(2000)\n",
    "\n",
    "# remove stopwords\n",
    "filtered_words = [word_tuple for word_tuple in most_common if word_tuple[0].lower() not in stopwords]\n",
    "# remove punctuation marks\n",
    "filtered_words = [word_tuple for word_tuple in filtered_words if word_tuple[0].isalpha()]\n",
    "print(len(filtered_words))\n",
    "filtered_words[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  extract this word list from the frequency tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1821"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features =  [word_tuple[0] for word_tuple in filtered_words]\n",
    "len(word_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function that takes a document and returns a list of zeros and ones indicating which of the words in  `word_features` appears in that document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = np.zeros(len(word_features))\n",
    "    for i, word in enumerate(word_features):\n",
    "        features[i] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just focus on the third document. Which words from `word_features` are in this document? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n",
      "\n",
      " ['film', 'one', 'movie', 'like', 'even', 'time', 'would', 'much', 'two', 'characters', 'first', 'way', 'make', 'really', 'films', 'plot', 'man', 'best', 'know', 'movies', 'go', 'us', 'however', 'every', 'audience', 'enough', 'seen', 'gets', 'things', 'long', 'thing', 'fact', 'nothing', 'cast', 'plays', 'young', 'show', 'comes', 'screen', 'acting', 'three', 'course', 'minutes', 'watch', 'hard', 'seem', 'times', 'instead', 'american', 'half', 'everything', 'becomes', 'dialogue', 'looking', 'watching', 'music', 'especially', 'simply', 'shows', 'written', 'name', 'based', 'wrong', 'unfortunately', 'hand', 'certainly', 'hour', 'despite', 'nice', 'seeing', 'video', 'car', 'matter', 'lines', 'worth', 'care', 'production', 'already', 'sometimes', 'save', 'attempt', 'tells', 'quickly', 'extremely', 'appears', 'police', 'single', 'late', 'elements', 'number', 'television', 'viewer', 'tale', 'cool', 'stuff', 'cop', 'complete', 'clear', 'towards', 'predictable', 'r', 'likely', 'immediately', 'mess', 'escape', 'ultimately', 'teen', 'rating', 'soundtrack', 'memorable', 'six', 'quick', 'cute', 'sounds', 'telling', 'awful', 'onto', 'apart', 'missing', 'cross', 'hair', 'literally', 'teenage', 'older', 'heroes', 'apparent', 'information', 'crazy', 'poorly', 'target', 'deliver', 'cash', 'avoid', 'nobody', 'spectacular', 'bored', 'flicks', 'content', 'clich', 'costumes', 'claire']\n"
     ]
    }
   ],
   "source": [
    "words_in_doc_2 = document_features(doc_words[2])\n",
    "print(words_in_doc_2)\n",
    "\n",
    "inds = np.where(words_in_doc_2 == 1)[0]\n",
    "print('\\n', [word_features[i] for i in inds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build our feature set for all the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.],\n",
       "       [1., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 1., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.zeros([num_reviews,len(word_features)])\n",
    "for i in range(num_reviews):\n",
    "    X[i,:] = document_features(doc_words[i])\n",
    "\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a feature vector for each of these reviews that we can use in classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have features for each document and labels, **we have a classification problem!** \n",
    "\n",
    "NLTK has a built-in classifier, but we'll use the scikit-learn classifiers we're already familiar with. \n",
    "\n",
    "Let's try k-nearest neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.595 0.63  0.53  0.63  0.64  0.555 0.625 0.685 0.635 0.63 ]\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "model = KNeighborsClassifier(n_neighbors=k)\n",
    "scores = cross_val_score(model, X, y, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78  0.83  0.855 0.815 0.825 0.85  0.835 0.84  0.79  0.86 ]\n"
     ]
    }
   ],
   "source": [
    "model = svm.SVC(kernel='rbf', C=30, gamma=\"auto\")\n",
    "scores = cross_val_score(model, X, y, cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that kNN with these parameters is less accurate than SVM, which is about 80% accurate. Of course, we could now use cross validation to find the optimal parameters, `k` and `C`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's see what our algorithm things about the Mod Squad! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=30, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, random_state=1, test_size=0.2)\n",
    "\n",
    "model.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1., ..., 0., 0., 0.])]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_squad = [X[2]]\n",
    "mod_squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(mod_squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model says 0 - so a bad review! We have succesfully build a classifier that can detect the Mod Squad review as a bad review! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a mis-classified movie. Remember, that the first 1000 movies are negative reviews, so we can just look for the first negative one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review 9, which was misclassified, is for Aberdeen, which has [generally favorable reviews](https://www.rottentomatoes.com/m/aberdeen/) with about 80% positive. Let's looks at the review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " call it a road trip for the walking wounded . \n",
      "stellan skarsg ? rd plays such a convincingly zombified drunken loser that it's difficult to spend nearly two hours of screen time in his smelly , boozed-out presence . \n",
      "yet this ever-reliable swedish actor adds depth and significance to the otherwise plodding and forgettable aberdeen , a sentimental and painfully mundane european drama . \n",
      "playwright august strindberg built his career on families and relationships paralyzed by secrets , unable to express their longings until the hour is far too late . \n",
      "that's an accurate reflection of what aberdeen strives for , focusing on the pairing of an alcoholic father , tomas ( skarsg ? rd ) and his alienated , openly hostile yuppie daughter , kaisa ( lena headey , gossip ) . \n",
      "they haven't spoken in years , and wouldn't even be making the long trip from norway to aberdeen , scotland by automobile if it weren't for kaisa's mother ( charlotte rampling , under the sand ) rotting away in a hospital bed from cancer . \n",
      "in a soap opera twist , mother has only a few days to live . \n",
      " ( only in the movies , right ? ) \n",
      "too blitzed to even step foot on a plane , tomas hits the open road with kaisa . \n",
      "loathing each other all the while , they make periodic stops for tomas to puke on the dashboard or pass out -- whenever he isn't muttering what a rotten kid she turned out to be . \n",
      "despite his sloshed viewpoint , tomas recognizes that the apple hasn't fallen very far from the tree . \n",
      "kaisa gets nosebleeds from snorting coke , sabotages her personal relationships through indifference , and is unable to restrain her quick and vindictive temper . \n",
      "ain't they a pair ? \n",
      "unable to find true notes of unspoken familial empathy in the one-note and repetitively bitchy dialogue , screenwriters kristin amundsen and hans petter moland fabricate a series of contrivances to propel events forward -- lost money , roving street hooligans looking for drunks to kick around , nosy cops , and flat tires all figure into the schematic and convenient narrative . \n",
      "by the time they reach the hospital , it's time to unveil the secrets from a dark past that are not only simplistic devices that trivialize the father-daughter conflict , they're also the mainstays of many a bad strindberg wannabe . \n",
      "this revelation exists purely for its own sake . \n",
      "aberdeen doesn't know where else to go . \n",
      "weak , unimaginative casting thwarts the pivotal role of kaisa . \n",
      "if lena headey were a stronger actress , perhaps aberdeen could have been able to coast on the performances and moody , haunting cinematography ( rendering norway into its own pastoral ghost world -- the reference to a certain superior american indie flick intentional ) . \n",
      "headey's too busy acting , using her face and furrowed brow to convey every last twitch of insouciance . \n",
      "if she were paying any attention to skarsg ? rd , maybe she'd figure out that doing less can reveal so much more . \n",
      "it's worthwhile to compare aberdeen to an earlier film released in 2001 , jonathan nossiter's captivating signs & wonders . \n",
      "it's not just because skarsg ? rd and rampling played disturbed parental figures in both films ( they're not bound by ceremonial wedlock in aberdeen ) . \n",
      "the differences in the way their characters were presented is significant . \n",
      "in aberdeen , rampling is a luminous diva , preening and static in her hospital bed . \n",
      "despite skarsg ? rd's solid performance as tomas , his pathetic drunk is never given much of a chance to emote anything besides catatonic sorrow . \n",
      "there's genuine ferocity and sexually charged frisson during their understated confrontations in signs & wonders , allowing them to suggest a gray zone of complications that accompany torn romance and years of stifled curiosity . \n",
      "nossiter's film thoroughly explores this neurotic territory in addition to delving into the americanization of greece and the use of mysticism as an illusion to deflect pain . \n",
      "if signs & wonders sometimes feels overloaded with ideas , at least it's willing to stretch beyond what we've come to expect from traditional drama . \n",
      "aberdeen is never half so ambitious , content to sleepwalk through the rhythms and timing of other movies . \n",
      "when did character driven stories stop paying attention to the complexities of real life ? \n",
      "the depressing answer can be found in lawrence kasdan's trite but occasionally useful grand canyon , where steve martin's hollywood mogul pronounces , \" all of life's riddles are answered in the movies ! \" \n",
      "even foreign films are taking that advice to heart . \n",
      "\n",
      "\n",
      " ['neg']\n"
     ]
    }
   ],
   "source": [
    "fid = reviews.fileids()[8]\n",
    "\n",
    "print('\\n', reviews.raw(fid))\n",
    "print('\\n', reviews.categories(fid) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we read this, we can see that this is a negative review, but not a terrible review. Take this sentence for example: \n",
    "\n",
    " * \"if signs & wonders sometimes feels overloaded with ideas , at least it's willing to stretch beyond what we've come to expect from traditional drama\"\n",
    " * \"yet this ever-reliable swedish actor adds depth and significance to the otherwise plodding and forgettable aberdeen , a sentimental and painfully mundane european drama\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We could have also used the Classifier from the NLTK library\n",
    "\n",
    "Below is the sentiment analysis from [Ch. 6 of the NLTK book](http://www.nltk.org/book/ch06.html). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(reviews.words(fileid)), category)\n",
    "             for category in reviews.categories() \n",
    "             for fileid in reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This list contains tuples where the review, stored as an array of words, is the first item in the tuple and the category is the second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'happy',\n",
       "  'bastard',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'quick',\n",
       "  'movie',\n",
       "  'review',\n",
       "  'damn',\n",
       "  'that',\n",
       "  'y2k',\n",
       "  'bug',\n",
       "  '.',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'got',\n",
       "  'a',\n",
       "  'head',\n",
       "  'start',\n",
       "  'in',\n",
       "  'this',\n",
       "  'movie',\n",
       "  'starring',\n",
       "  'jamie',\n",
       "  'lee',\n",
       "  'curtis',\n",
       "  'and',\n",
       "  'another',\n",
       "  'baldwin',\n",
       "  'brother',\n",
       "  '(',\n",
       "  'william',\n",
       "  'this',\n",
       "  'time',\n",
       "  ')',\n",
       "  'in',\n",
       "  'a',\n",
       "  'story',\n",
       "  'regarding',\n",
       "  'a',\n",
       "  'crew',\n",
       "  'of',\n",
       "  'a',\n",
       "  'tugboat',\n",
       "  'that',\n",
       "  'comes',\n",
       "  'across',\n",
       "  'a',\n",
       "  'deserted',\n",
       "  'russian',\n",
       "  'tech',\n",
       "  'ship',\n",
       "  'that',\n",
       "  'has',\n",
       "  'a',\n",
       "  'strangeness',\n",
       "  'to',\n",
       "  'it',\n",
       "  'when',\n",
       "  'they',\n",
       "  'kick',\n",
       "  'the',\n",
       "  'power',\n",
       "  'back',\n",
       "  'on',\n",
       "  '.',\n",
       "  'little',\n",
       "  'do',\n",
       "  'they',\n",
       "  'know',\n",
       "  'the',\n",
       "  'power',\n",
       "  'within',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'going',\n",
       "  'for',\n",
       "  'the',\n",
       "  'gore',\n",
       "  'and',\n",
       "  'bringing',\n",
       "  'on',\n",
       "  'a',\n",
       "  'few',\n",
       "  'action',\n",
       "  'sequences',\n",
       "  'here',\n",
       "  'and',\n",
       "  'there',\n",
       "  ',',\n",
       "  'virus',\n",
       "  'still',\n",
       "  'feels',\n",
       "  'very',\n",
       "  'empty',\n",
       "  ',',\n",
       "  'like',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'going',\n",
       "  'for',\n",
       "  'all',\n",
       "  'flash',\n",
       "  'and',\n",
       "  'no',\n",
       "  'substance',\n",
       "  '.',\n",
       "  'we',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'why',\n",
       "  'the',\n",
       "  'crew',\n",
       "  'was',\n",
       "  'really',\n",
       "  'out',\n",
       "  'in',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'of',\n",
       "  'nowhere',\n",
       "  ',',\n",
       "  'we',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'the',\n",
       "  'origin',\n",
       "  'of',\n",
       "  'what',\n",
       "  'took',\n",
       "  'over',\n",
       "  'the',\n",
       "  'ship',\n",
       "  '(',\n",
       "  'just',\n",
       "  'that',\n",
       "  'a',\n",
       "  'big',\n",
       "  'pink',\n",
       "  'flashy',\n",
       "  'thing',\n",
       "  'hit',\n",
       "  'the',\n",
       "  'mir',\n",
       "  ')',\n",
       "  ',',\n",
       "  'and',\n",
       "  ',',\n",
       "  'of',\n",
       "  'course',\n",
       "  ',',\n",
       "  'we',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'why',\n",
       "  'donald',\n",
       "  'sutherland',\n",
       "  'is',\n",
       "  'stumbling',\n",
       "  'around',\n",
       "  'drunkenly',\n",
       "  'throughout',\n",
       "  '.',\n",
       "  'here',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'just',\n",
       "  '\"',\n",
       "  'hey',\n",
       "  ',',\n",
       "  'let',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'chase',\n",
       "  'these',\n",
       "  'people',\n",
       "  'around',\n",
       "  'with',\n",
       "  'some',\n",
       "  'robots',\n",
       "  '\"',\n",
       "  '.',\n",
       "  'the',\n",
       "  'acting',\n",
       "  'is',\n",
       "  'below',\n",
       "  'average',\n",
       "  ',',\n",
       "  'even',\n",
       "  'from',\n",
       "  'the',\n",
       "  'likes',\n",
       "  'of',\n",
       "  'curtis',\n",
       "  '.',\n",
       "  'you',\n",
       "  \"'\",\n",
       "  're',\n",
       "  'more',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'kick',\n",
       "  'out',\n",
       "  'of',\n",
       "  'her',\n",
       "  'work',\n",
       "  'in',\n",
       "  'halloween',\n",
       "  'h20',\n",
       "  '.',\n",
       "  'sutherland',\n",
       "  'is',\n",
       "  'wasted',\n",
       "  'and',\n",
       "  'baldwin',\n",
       "  ',',\n",
       "  'well',\n",
       "  ',',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'acting',\n",
       "  'like',\n",
       "  'a',\n",
       "  'baldwin',\n",
       "  ',',\n",
       "  'of',\n",
       "  'course',\n",
       "  '.',\n",
       "  'the',\n",
       "  'real',\n",
       "  'star',\n",
       "  'here',\n",
       "  'are',\n",
       "  'stan',\n",
       "  'winston',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'robot',\n",
       "  'design',\n",
       "  ',',\n",
       "  'some',\n",
       "  'schnazzy',\n",
       "  'cgi',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'occasional',\n",
       "  'good',\n",
       "  'gore',\n",
       "  'shot',\n",
       "  ',',\n",
       "  'like',\n",
       "  'picking',\n",
       "  'into',\n",
       "  'someone',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'brain',\n",
       "  '.',\n",
       "  'so',\n",
       "  ',',\n",
       "  'if',\n",
       "  'robots',\n",
       "  'and',\n",
       "  'body',\n",
       "  'parts',\n",
       "  'really',\n",
       "  'turn',\n",
       "  'you',\n",
       "  'on',\n",
       "  ',',\n",
       "  'here',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'your',\n",
       "  'movie',\n",
       "  '.',\n",
       "  'otherwise',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'pretty',\n",
       "  'much',\n",
       "  'a',\n",
       "  'sunken',\n",
       "  'ship',\n",
       "  'of',\n",
       "  'a',\n",
       "  'movie',\n",
       "  '.'],\n",
       " 'neg')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features from all of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document):    \n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(film)': True,\n",
       "  'contains(one)': True,\n",
       "  'contains(movie)': True,\n",
       "  'contains(like)': True,\n",
       "  'contains(even)': True,\n",
       "  'contains(good)': False,\n",
       "  'contains(time)': True,\n",
       "  'contains(story)': False,\n",
       "  'contains(would)': True,\n",
       "  'contains(much)': True,\n",
       "  'contains(character)': False,\n",
       "  'contains(also)': False,\n",
       "  'contains(get)': False,\n",
       "  'contains(two)': True,\n",
       "  'contains(well)': False,\n",
       "  'contains(characters)': True,\n",
       "  'contains(first)': True,\n",
       "  'contains(see)': False,\n",
       "  'contains(way)': True,\n",
       "  'contains(make)': True,\n",
       "  'contains(life)': False,\n",
       "  'contains(really)': True,\n",
       "  'contains(films)': True,\n",
       "  'contains(plot)': True,\n",
       "  'contains(little)': False,\n",
       "  'contains(people)': False,\n",
       "  'contains(could)': False,\n",
       "  'contains(scene)': False,\n",
       "  'contains(man)': True,\n",
       "  'contains(bad)': False,\n",
       "  'contains(never)': False,\n",
       "  'contains(best)': True,\n",
       "  'contains(new)': False,\n",
       "  'contains(scenes)': False,\n",
       "  'contains(many)': False,\n",
       "  'contains(director)': False,\n",
       "  'contains(know)': True,\n",
       "  'contains(movies)': True,\n",
       "  'contains(action)': False,\n",
       "  'contains(great)': False,\n",
       "  'contains(another)': False,\n",
       "  'contains(love)': False,\n",
       "  'contains(go)': True,\n",
       "  'contains(made)': False,\n",
       "  'contains(us)': True,\n",
       "  'contains(big)': False,\n",
       "  'contains(end)': False,\n",
       "  'contains(something)': False,\n",
       "  'contains(back)': False,\n",
       "  'contains(still)': False,\n",
       "  'contains(world)': False,\n",
       "  'contains(seems)': False,\n",
       "  'contains(work)': False,\n",
       "  'contains(makes)': False,\n",
       "  'contains(however)': True,\n",
       "  'contains(every)': True,\n",
       "  'contains(though)': False,\n",
       "  'contains(better)': False,\n",
       "  'contains(real)': False,\n",
       "  'contains(audience)': True,\n",
       "  'contains(enough)': True,\n",
       "  'contains(seen)': True,\n",
       "  'contains(take)': False,\n",
       "  'contains(around)': False,\n",
       "  'contains(going)': False,\n",
       "  'contains(year)': False,\n",
       "  'contains(performance)': False,\n",
       "  'contains(role)': False,\n",
       "  'contains(old)': False,\n",
       "  'contains(gets)': True,\n",
       "  'contains(may)': False,\n",
       "  'contains(things)': True,\n",
       "  'contains(think)': False,\n",
       "  'contains(years)': False,\n",
       "  'contains(last)': False,\n",
       "  'contains(comedy)': False,\n",
       "  'contains(funny)': False,\n",
       "  'contains(actually)': False,\n",
       "  'contains(long)': True,\n",
       "  'contains(look)': False,\n",
       "  'contains(almost)': False,\n",
       "  'contains(thing)': True,\n",
       "  'contains(fact)': True,\n",
       "  'contains(nothing)': True,\n",
       "  'contains(say)': False,\n",
       "  'contains(right)': False,\n",
       "  'contains(john)': False,\n",
       "  'contains(although)': False,\n",
       "  'contains(played)': False,\n",
       "  'contains(find)': False,\n",
       "  'contains(script)': False,\n",
       "  'contains(come)': False,\n",
       "  'contains(ever)': False,\n",
       "  'contains(cast)': True,\n",
       "  'contains(since)': False,\n",
       "  'contains(star)': False,\n",
       "  'contains(plays)': True,\n",
       "  'contains(young)': True,\n",
       "  'contains(show)': True,\n",
       "  'contains(comes)': True,\n",
       "  'contains(part)': False,\n",
       "  'contains(original)': False,\n",
       "  'contains(actors)': False,\n",
       "  'contains(screen)': True,\n",
       "  'contains(without)': False,\n",
       "  'contains(acting)': True,\n",
       "  'contains(three)': True,\n",
       "  'contains(day)': False,\n",
       "  'contains(point)': False,\n",
       "  'contains(lot)': False,\n",
       "  'contains(least)': False,\n",
       "  'contains(takes)': False,\n",
       "  'contains(guy)': False,\n",
       "  'contains(quite)': False,\n",
       "  'contains(away)': False,\n",
       "  'contains(family)': False,\n",
       "  'contains(effects)': False,\n",
       "  'contains(course)': True,\n",
       "  'contains(goes)': False,\n",
       "  'contains(minutes)': True,\n",
       "  'contains(interesting)': False,\n",
       "  'contains(might)': False,\n",
       "  'contains(far)': False,\n",
       "  'contains(high)': False,\n",
       "  'contains(rather)': False,\n",
       "  'contains(must)': False,\n",
       "  'contains(anything)': False,\n",
       "  'contains(place)': False,\n",
       "  'contains(set)': False,\n",
       "  'contains(yet)': False,\n",
       "  'contains(watch)': True,\n",
       "  'contains(making)': False,\n",
       "  'contains(wife)': False,\n",
       "  'contains(hard)': True,\n",
       "  'contains(always)': False,\n",
       "  'contains(fun)': False,\n",
       "  'contains(seem)': True,\n",
       "  'contains(special)': False,\n",
       "  'contains(bit)': False,\n",
       "  'contains(times)': True,\n",
       "  'contains(trying)': False,\n",
       "  'contains(hollywood)': False,\n",
       "  'contains(instead)': True,\n",
       "  'contains(give)': False,\n",
       "  'contains(want)': False,\n",
       "  'contains(picture)': False,\n",
       "  'contains(kind)': False,\n",
       "  'contains(american)': True,\n",
       "  'contains(job)': False,\n",
       "  'contains(sense)': False,\n",
       "  'contains(woman)': False,\n",
       "  'contains(home)': False,\n",
       "  'contains(series)': False,\n",
       "  'contains(actor)': False,\n",
       "  'contains(probably)': False,\n",
       "  'contains(help)': False,\n",
       "  'contains(half)': True,\n",
       "  'contains(along)': False,\n",
       "  'contains(men)': False,\n",
       "  'contains(everything)': True,\n",
       "  'contains(pretty)': False,\n",
       "  'contains(becomes)': True,\n",
       "  'contains(sure)': False,\n",
       "  'contains(black)': False,\n",
       "  'contains(together)': False,\n",
       "  'contains(dialogue)': True,\n",
       "  'contains(money)': False,\n",
       "  'contains(become)': False,\n",
       "  'contains(gives)': False,\n",
       "  'contains(given)': False,\n",
       "  'contains(looking)': True,\n",
       "  'contains(whole)': False,\n",
       "  'contains(watching)': True,\n",
       "  'contains(father)': False,\n",
       "  'contains(feel)': False,\n",
       "  'contains(everyone)': False,\n",
       "  'contains(music)': True,\n",
       "  'contains(wants)': False,\n",
       "  'contains(sex)': False,\n",
       "  'contains(less)': False,\n",
       "  'contains(done)': False,\n",
       "  'contains(horror)': False,\n",
       "  'contains(got)': False,\n",
       "  'contains(death)': False,\n",
       "  'contains(perhaps)': False,\n",
       "  'contains(city)': False,\n",
       "  'contains(next)': False,\n",
       "  'contains(especially)': True,\n",
       "  'contains(play)': False,\n",
       "  'contains(girl)': False,\n",
       "  'contains(mind)': False,\n",
       "  'contains(moments)': False,\n",
       "  'contains(looks)': False,\n",
       "  'contains(completely)': False,\n",
       "  'contains(reason)': False,\n",
       "  'contains(mother)': False,\n",
       "  'contains(whose)': False,\n",
       "  'contains(line)': False,\n",
       "  'contains(night)': False,\n",
       "  'contains(human)': False,\n",
       "  'contains(rest)': False,\n",
       "  'contains(performances)': False,\n",
       "  'contains(different)': False,\n",
       "  'contains(evil)': False,\n",
       "  'contains(small)': False,\n",
       "  'contains(james)': False,\n",
       "  'contains(simply)': True,\n",
       "  'contains(couple)': False,\n",
       "  'contains(put)': False,\n",
       "  'contains(let)': False,\n",
       "  'contains(anyone)': False,\n",
       "  'contains(ending)': False,\n",
       "  'contains(case)': False,\n",
       "  'contains(several)': False,\n",
       "  'contains(dead)': False,\n",
       "  'contains(michael)': False,\n",
       "  'contains(left)': False,\n",
       "  'contains(thought)': False,\n",
       "  'contains(school)': False,\n",
       "  'contains(shows)': True,\n",
       "  'contains(humor)': False,\n",
       "  'contains(true)': False,\n",
       "  'contains(lost)': False,\n",
       "  'contains(written)': True,\n",
       "  'contains(friend)': False,\n",
       "  'contains(entire)': False,\n",
       "  'contains(getting)': False,\n",
       "  'contains(town)': False,\n",
       "  'contains(turns)': False,\n",
       "  'contains(soon)': False,\n",
       "  'contains(someone)': False,\n",
       "  'contains(second)': False,\n",
       "  'contains(main)': False,\n",
       "  'contains(stars)': False,\n",
       "  'contains(found)': False,\n",
       "  'contains(use)': False,\n",
       "  'contains(problem)': False,\n",
       "  'contains(friends)': False,\n",
       "  'contains(tv)': False,\n",
       "  'contains(top)': False,\n",
       "  'contains(name)': True,\n",
       "  'contains(begins)': False,\n",
       "  'contains(called)': False,\n",
       "  'contains(based)': True,\n",
       "  'contains(comic)': False,\n",
       "  'contains(david)': False,\n",
       "  'contains(head)': False,\n",
       "  'contains(else)': False,\n",
       "  'contains(idea)': False,\n",
       "  'contains(either)': False,\n",
       "  'contains(wrong)': True,\n",
       "  'contains(unfortunately)': True,\n",
       "  'contains(later)': False,\n",
       "  'contains(final)': False,\n",
       "  'contains(hand)': True,\n",
       "  'contains(alien)': False,\n",
       "  'contains(house)': False,\n",
       "  'contains(group)': False,\n",
       "  'contains(full)': False,\n",
       "  'contains(used)': False,\n",
       "  'contains(tries)': False,\n",
       "  'contains(often)': False,\n",
       "  'contains(war)': False,\n",
       "  'contains(sequence)': False,\n",
       "  'contains(keep)': False,\n",
       "  'contains(turn)': False,\n",
       "  'contains(playing)': False,\n",
       "  'contains(boy)': False,\n",
       "  'contains(behind)': False,\n",
       "  'contains(named)': False,\n",
       "  'contains(certainly)': True,\n",
       "  'contains(live)': False,\n",
       "  'contains(believe)': False,\n",
       "  'contains(works)': False,\n",
       "  'contains(relationship)': False,\n",
       "  'contains(face)': False,\n",
       "  'contains(hour)': True,\n",
       "  'contains(run)': False,\n",
       "  'contains(style)': False,\n",
       "  'contains(said)': False,\n",
       "  'contains(despite)': True,\n",
       "  'contains(person)': False,\n",
       "  'contains(finally)': False,\n",
       "  'contains(shot)': False,\n",
       "  'contains(book)': False,\n",
       "  'contains(tell)': False,\n",
       "  'contains(maybe)': False,\n",
       "  'contains(nice)': True,\n",
       "  'contains(son)': False,\n",
       "  'contains(perfect)': False,\n",
       "  'contains(side)': False,\n",
       "  'contains(seeing)': True,\n",
       "  'contains(able)': False,\n",
       "  'contains(finds)': False,\n",
       "  'contains(children)': False,\n",
       "  'contains(days)': False,\n",
       "  'contains(past)': False,\n",
       "  'contains(summer)': False,\n",
       "  'contains(camera)': False,\n",
       "  'contains(including)': False,\n",
       "  'contains(mr)': False,\n",
       "  'contains(kids)': False,\n",
       "  'contains(lives)': False,\n",
       "  'contains(directed)': False,\n",
       "  'contains(moment)': False,\n",
       "  'contains(game)': False,\n",
       "  'contains(running)': False,\n",
       "  'contains(fight)': False,\n",
       "  'contains(supposed)': False,\n",
       "  'contains(video)': True,\n",
       "  'contains(car)': True,\n",
       "  'contains(matter)': True,\n",
       "  'contains(kevin)': False,\n",
       "  'contains(joe)': False,\n",
       "  'contains(lines)': True,\n",
       "  'contains(worth)': True,\n",
       "  'contains(daughter)': False,\n",
       "  'contains(earth)': False,\n",
       "  'contains(starts)': False,\n",
       "  'contains(need)': False,\n",
       "  'contains(entertaining)': False,\n",
       "  'contains(white)': False,\n",
       "  'contains(start)': False,\n",
       "  'contains(writer)': False,\n",
       "  'contains(dark)': False,\n",
       "  'contains(short)': False,\n",
       "  'contains(self)': False,\n",
       "  'contains(worst)': False,\n",
       "  'contains(nearly)': False,\n",
       "  'contains(opening)': False,\n",
       "  'contains(try)': False,\n",
       "  'contains(upon)': False,\n",
       "  'contains(care)': True,\n",
       "  'contains(early)': False,\n",
       "  'contains(violence)': False,\n",
       "  'contains(throughout)': False,\n",
       "  'contains(team)': False,\n",
       "  'contains(production)': True,\n",
       "  'contains(example)': False,\n",
       "  'contains(beautiful)': False,\n",
       "  'contains(title)': False,\n",
       "  'contains(exactly)': False,\n",
       "  'contains(jack)': False,\n",
       "  'contains(review)': False,\n",
       "  'contains(major)': False,\n",
       "  'contains(drama)': False,\n",
       "  'contains(problems)': False,\n",
       "  'contains(sequences)': False,\n",
       "  'contains(obvious)': False,\n",
       "  'contains(version)': False,\n",
       "  'contains(screenplay)': False,\n",
       "  'contains(known)': False,\n",
       "  'contains(killer)': False,\n",
       "  'contains(robert)': False,\n",
       "  'contains(disney)': False,\n",
       "  'contains(already)': True,\n",
       "  'contains(close)': False,\n",
       "  'contains(classic)': False,\n",
       "  'contains(others)': False,\n",
       "  'contains(hit)': False,\n",
       "  'contains(kill)': False,\n",
       "  'contains(deep)': False,\n",
       "  'contains(five)': False,\n",
       "  'contains(order)': False,\n",
       "  'contains(act)': False,\n",
       "  'contains(simple)': False,\n",
       "  'contains(fine)': False,\n",
       "  'contains(heart)': False,\n",
       "  'contains(roles)': False,\n",
       "  'contains(jackie)': False,\n",
       "  'contains(direction)': False,\n",
       "  'contains(eyes)': False,\n",
       "  'contains(four)': False,\n",
       "  'contains(question)': False,\n",
       "  'contains(sort)': False,\n",
       "  'contains(sometimes)': True,\n",
       "  'contains(knows)': False,\n",
       "  'contains(supporting)': False,\n",
       "  'contains(coming)': False,\n",
       "  'contains(voice)': False,\n",
       "  'contains(women)': False,\n",
       "  'contains(truly)': False,\n",
       "  'contains(save)': True,\n",
       "  'contains(jokes)': False,\n",
       "  'contains(computer)': False,\n",
       "  'contains(child)': False,\n",
       "  'contains(boring)': False,\n",
       "  'contains(tom)': False,\n",
       "  'contains(level)': False,\n",
       "  'contains(body)': False,\n",
       "  'contains(guys)': False,\n",
       "  'contains(genre)': False,\n",
       "  'contains(brother)': False,\n",
       "  'contains(strong)': False,\n",
       "  'contains(stop)': False,\n",
       "  'contains(room)': False,\n",
       "  'contains(space)': False,\n",
       "  'contains(lee)': False,\n",
       "  'contains(ends)': False,\n",
       "  'contains(beginning)': False,\n",
       "  'contains(ship)': False,\n",
       "  'contains(york)': False,\n",
       "  'contains(attempt)': True,\n",
       "  'contains(thriller)': False,\n",
       "  'contains(scream)': False,\n",
       "  'contains(peter)': False,\n",
       "  'contains(husband)': False,\n",
       "  'contains(fiction)': False,\n",
       "  'contains(happens)': False,\n",
       "  'contains(hero)': False,\n",
       "  'contains(novel)': False,\n",
       "  'contains(note)': False,\n",
       "  'contains(hope)': False,\n",
       "  'contains(king)': False,\n",
       "  'contains(yes)': False,\n",
       "  'contains(says)': False,\n",
       "  'contains(tells)': True,\n",
       "  'contains(quickly)': True,\n",
       "  'contains(romantic)': False,\n",
       "  'contains(dog)': False,\n",
       "  'contains(oscar)': False,\n",
       "  'contains(stupid)': False,\n",
       "  'contains(possible)': False,\n",
       "  'contains(saw)': False,\n",
       "  'contains(lead)': False,\n",
       "  'contains(career)': False,\n",
       "  'contains(murder)': False,\n",
       "  'contains(extremely)': True,\n",
       "  'contains(manages)': False,\n",
       "  'contains(god)': False,\n",
       "  'contains(mostly)': False,\n",
       "  'contains(wonder)': False,\n",
       "  'contains(particularly)': False,\n",
       "  'contains(future)': False,\n",
       "  'contains(fans)': False,\n",
       "  'contains(sound)': False,\n",
       "  'contains(worse)': False,\n",
       "  'contains(piece)': False,\n",
       "  'contains(involving)': False,\n",
       "  'contains(de)': False,\n",
       "  'contains(appears)': True,\n",
       "  'contains(planet)': False,\n",
       "  'contains(paul)': False,\n",
       "  'contains(involved)': False,\n",
       "  'contains(mean)': False,\n",
       "  'contains(none)': False,\n",
       "  'contains(taking)': False,\n",
       "  'contains(hours)': False,\n",
       "  'contains(laugh)': False,\n",
       "  'contains(police)': True,\n",
       "  'contains(sets)': False,\n",
       "  'contains(attention)': False,\n",
       "  'contains(co)': False,\n",
       "  'contains(hell)': False,\n",
       "  'contains(eventually)': False,\n",
       "  'contains(single)': True,\n",
       "  'contains(fall)': False,\n",
       "  'contains(falls)': False,\n",
       "  'contains(material)': False,\n",
       "  'contains(emotional)': False,\n",
       "  'contains(power)': False,\n",
       "  'contains(late)': True,\n",
       "  'contains(lack)': False,\n",
       "  'contains(dr)': False,\n",
       "  'contains(van)': False,\n",
       "  'contains(result)': False,\n",
       "  'contains(elements)': True,\n",
       "  'contains(meet)': False,\n",
       "  'contains(smith)': False,\n",
       "  'contains(science)': False,\n",
       "  'contains(experience)': False,\n",
       "  'contains(bring)': False,\n",
       "  'contains(wild)': False,\n",
       "  'contains(living)': False,\n",
       "  'contains(theater)': False,\n",
       "  'contains(interest)': False,\n",
       "  'contains(leads)': False,\n",
       "  'contains(word)': False,\n",
       "  'contains(feature)': False,\n",
       "  'contains(battle)': False,\n",
       "  'contains(girls)': False,\n",
       "  'contains(alone)': False,\n",
       "  'contains(obviously)': False,\n",
       "  'contains(george)': False,\n",
       "  'contains(within)': False,\n",
       "  'contains(usually)': False,\n",
       "  'contains(enjoy)': False,\n",
       "  'contains(guess)': False,\n",
       "  'contains(among)': False,\n",
       "  'contains(taken)': False,\n",
       "  'contains(feeling)': False,\n",
       "  'contains(laughs)': False,\n",
       "  'contains(aliens)': False,\n",
       "  'contains(talk)': False,\n",
       "  'contains(chance)': False,\n",
       "  'contains(talent)': False,\n",
       "  'contains(middle)': False,\n",
       "  'contains(number)': True,\n",
       "  'contains(easy)': False,\n",
       "  'contains(across)': False,\n",
       "  'contains(needs)': False,\n",
       "  'contains(attempts)': False,\n",
       "  'contains(happen)': False,\n",
       "  'contains(television)': True,\n",
       "  'contains(chris)': False,\n",
       "  'contains(deal)': False,\n",
       "  'contains(poor)': False,\n",
       "  'contains(form)': False,\n",
       "  'contains(girlfriend)': False,\n",
       "  'contains(viewer)': True,\n",
       "  'contains(release)': False,\n",
       "  'contains(killed)': False,\n",
       "  'contains(forced)': False,\n",
       "  'contains(whether)': False,\n",
       "  'contains(wonderful)': False,\n",
       "  'contains(feels)': False,\n",
       "  'contains(oh)': False,\n",
       "  'contains(tale)': True,\n",
       "  'contains(serious)': False,\n",
       "  'contains(expect)': False,\n",
       "  'contains(except)': False,\n",
       "  'contains(light)': False,\n",
       "  'contains(success)': False,\n",
       "  'contains(features)': False,\n",
       "  'contains(premise)': False,\n",
       "  'contains(happy)': False,\n",
       "  'contains(words)': False,\n",
       "  'contains(leave)': False,\n",
       "  'contains(important)': False,\n",
       "  'contains(meets)': False,\n",
       "  'contains(history)': False,\n",
       "  'contains(giving)': False,\n",
       "  'contains(crew)': False,\n",
       "  'contains(type)': False,\n",
       "  'contains(call)': False,\n",
       "  'contains(turned)': False,\n",
       "  'contains(released)': False,\n",
       "  'contains(parents)': False,\n",
       "  'contains(art)': False,\n",
       "  'contains(impressive)': False,\n",
       "  'contains(mission)': False,\n",
       "  'contains(working)': False,\n",
       "  'contains(seemed)': False,\n",
       "  'contains(score)': False,\n",
       "  'contains(told)': False,\n",
       "  'contains(recent)': False,\n",
       "  'contains(robin)': False,\n",
       "  'contains(basically)': False,\n",
       "  'contains(entertainment)': False,\n",
       "  'contains(america)': False,\n",
       "  'contains(surprise)': False,\n",
       "  'contains(apparently)': False,\n",
       "  'contains(easily)': False,\n",
       "  'contains(ryan)': False,\n",
       "  'contains(cool)': True,\n",
       "  'contains(stuff)': True,\n",
       "  'contains(cop)': True,\n",
       "  'contains(change)': False,\n",
       "  'contains(williams)': False,\n",
       "  'contains(crime)': False,\n",
       "  'contains(office)': False,\n",
       "  'contains(parts)': False,\n",
       "  'contains(somehow)': False,\n",
       "  'contains(sequel)': False,\n",
       "  'contains(william)': False,\n",
       "  'contains(cut)': False,\n",
       "  'contains(die)': False,\n",
       "  'contains(jones)': False,\n",
       "  'contains(credits)': False,\n",
       "  'contains(batman)': False,\n",
       "  'contains(suspense)': False,\n",
       "  'contains(brings)': False,\n",
       "  'contains(events)': False,\n",
       "  'contains(reality)': False,\n",
       "  'contains(local)': False,\n",
       "  'contains(talking)': False,\n",
       "  'contains(difficult)': False,\n",
       "  'contains(using)': False,\n",
       "  'contains(went)': False,\n",
       "  'contains(writing)': False,\n",
       "  'contains(remember)': False,\n",
       "  'contains(near)': False,\n",
       "  'contains(straight)': False,\n",
       "  'contains(hilarious)': False,\n",
       "  'contains(ago)': False,\n",
       "  'contains(certain)': False,\n",
       "  'contains(ben)': False,\n",
       "  'contains(kid)': False,\n",
       "  'contains(slow)': False,\n",
       "  'contains(blood)': False,\n",
       "  'contains(mystery)': False,\n",
       "  'contains(complete)': True,\n",
       "  'contains(red)': False,\n",
       "  'contains(popular)': False,\n",
       "  'contains(effective)': False,\n",
       "  'contains(fast)': False,\n",
       "  'contains(flick)': False,\n",
       "  'contains(due)': False,\n",
       "  'contains(runs)': False,\n",
       "  'contains(gone)': False,\n",
       "  'contains(return)': False,\n",
       "  'contains(presence)': False,\n",
       "  'contains(quality)': False,\n",
       "  'contains(dramatic)': False,\n",
       "  'contains(filmmakers)': False,\n",
       "  'contains(age)': False,\n",
       "  'contains(brothers)': False,\n",
       "  'contains(business)': False,\n",
       "  'contains(general)': False,\n",
       "  'contains(rock)': False,\n",
       "  'contains(sexual)': False,\n",
       "  'contains(present)': False,\n",
       "  'contains(surprisingly)': False,\n",
       "  'contains(anyway)': False,\n",
       "  'contains(uses)': False,\n",
       "  'contains(personal)': False,\n",
       "  'contains(figure)': False,\n",
       "  'contains(smart)': False,\n",
       "  'contains(ways)': False,\n",
       "  'contains(decides)': False,\n",
       "  'contains(annoying)': False,\n",
       "  'contains(begin)': False,\n",
       "  'contains(somewhat)': False,\n",
       "  'contains(shots)': False,\n",
       "  'contains(rich)': False,\n",
       "  'contains(minute)': False,\n",
       "  'contains(law)': False,\n",
       "  'contains(previous)': False,\n",
       "  'contains(jim)': False,\n",
       "  'contains(successful)': False,\n",
       "  'contains(harry)': False,\n",
       "  'contains(water)': False,\n",
       "  'contains(similar)': False,\n",
       "  'contains(absolutely)': False,\n",
       "  'contains(motion)': False,\n",
       "  'contains(former)': False,\n",
       "  'contains(strange)': False,\n",
       "  'contains(came)': False,\n",
       "  'contains(follow)': False,\n",
       "  'contains(read)': False,\n",
       "  'contains(project)': False,\n",
       "  'contains(million)': False,\n",
       "  'contains(secret)': False,\n",
       "  'contains(starring)': False,\n",
       "  'contains(clear)': True,\n",
       "  'contains(familiar)': False,\n",
       "  'contains(romance)': False,\n",
       "  'contains(intelligent)': False,\n",
       "  'contains(third)': False,\n",
       "  'contains(excellent)': False,\n",
       "  'contains(amazing)': False,\n",
       "  'contains(party)': False,\n",
       "  'contains(budget)': False,\n",
       "  'contains(eye)': False,\n",
       "  'contains(actress)': False,\n",
       "  'contains(prison)': False,\n",
       "  'contains(latest)': False,\n",
       "  'contains(means)': False,\n",
       "  'contains(company)': False,\n",
       "  'contains(towards)': True,\n",
       "  'contains(predictable)': True,\n",
       "  'contains(powerful)': False,\n",
       "  'contains(bob)': False,\n",
       "  'contains(beyond)': False,\n",
       "  'contains(visual)': False,\n",
       "  'contains(leaves)': False,\n",
       "  'contains(r)': True,\n",
       "  'contains(nature)': False,\n",
       "  'contains(following)': False,\n",
       "  'contains(villain)': False,\n",
       "  'contains(leaving)': False,\n",
       "  'contains(animated)': False,\n",
       "  'contains(low)': False,\n",
       "  'contains(b)': False,\n",
       "  'contains(bill)': False,\n",
       "  'contains(sam)': False,\n",
       "  'contains(filled)': False,\n",
       "  'contains(wars)': False,\n",
       "  'contains(questions)': False,\n",
       "  'contains(cinema)': False,\n",
       "  'contains(message)': False,\n",
       "  'contains(box)': False,\n",
       "  'contains(moving)': False,\n",
       "  'contains(country)': False,\n",
       "  'contains(usual)': False,\n",
       "  'contains(martin)': False,\n",
       "  'contains(definitely)': False,\n",
       "  'contains(add)': False,\n",
       "  'contains(large)': False,\n",
       "  'contains(clever)': False,\n",
       "  'contains(create)': False,\n",
       "  'contains(felt)': False,\n",
       "  'contains(stories)': False,\n",
       "  'contains(brilliant)': False,\n",
       "  'contains(ones)': False,\n",
       "  'contains(giant)': False,\n",
       "  'contains(situation)': False,\n",
       "  'contains(murphy)': False,\n",
       "  'contains(break)': False,\n",
       "  'contains(opens)': False,\n",
       "  'contains(scary)': False,\n",
       "  'contains(doubt)': False,\n",
       "  'contains(drug)': False,\n",
       "  'contains(bunch)': False,\n",
       "  'contains(thinking)': False,\n",
       "  'contains(solid)': False,\n",
       "  'contains(effect)': False,\n",
       "  'contains(learn)': False,\n",
       "  'contains(move)': False,\n",
       "  'contains(force)': False,\n",
       "  'contains(potential)': False,\n",
       "  'contains(seriously)': False,\n",
       "  'contains(follows)': False,\n",
       "  'contains(saying)': False,\n",
       "  'contains(huge)': False,\n",
       "  'contains(class)': False,\n",
       "  'contains(plan)': False,\n",
       "  'contains(agent)': False,\n",
       "  'contains(created)': False,\n",
       "  'contains(unlike)': False,\n",
       "  'contains(pay)': False,\n",
       "  'contains(non)': False,\n",
       "  'contains(married)': False,\n",
       "  'contains(mark)': False,\n",
       "  'contains(sweet)': False,\n",
       "  'contains(perfectly)': False,\n",
       "  'contains(ex)': False,\n",
       "  'contains(realize)': False,\n",
       "  'contains(audiences)': False,\n",
       "  'contains(took)': False,\n",
       "  'contains(decent)': False,\n",
       "  'contains(likely)': True,\n",
       "  'contains(dream)': False,\n",
       "  'contains(view)': False,\n",
       "  'contains(scott)': False,\n",
       "  'contains(subject)': False,\n",
       "  'contains(understand)': False,\n",
       "  'contains(happened)': False,\n",
       "  'contains(enjoyable)': False,\n",
       "  'contains(studio)': False,\n",
       "  'contains(immediately)': True,\n",
       "  'contains(open)': False,\n",
       "  'contains(e)': False,\n",
       "  'contains(points)': False,\n",
       "  'contains(heard)': False,\n",
       "  'contains(viewers)': False,\n",
       "  'contains(cameron)': False,\n",
       "  'contains(truman)': False,\n",
       "  'contains(bruce)': False,\n",
       "  'contains(frank)': False,\n",
       "  'contains(private)': False,\n",
       "  'contains(stay)': False,\n",
       "  'contains(fails)': False,\n",
       "  'contains(impossible)': False,\n",
       "  'contains(cold)': False,\n",
       "  'contains(richard)': False,\n",
       "  'contains(overall)': False,\n",
       "  'contains(merely)': False,\n",
       "  'contains(exciting)': False,\n",
       "  'contains(mess)': True,\n",
       "  'contains(chase)': False,\n",
       "  'contains(free)': False,\n",
       "  'contains(ten)': False,\n",
       "  'contains(neither)': False,\n",
       "  'contains(wanted)': False,\n",
       "  'contains(gun)': False,\n",
       "  'contains(appear)': False,\n",
       "  'contains(carter)': False,\n",
       "  'contains(escape)': True,\n",
       "  'contains(ultimately)': True,\n",
       "  'contains(fan)': False,\n",
       "  'contains(inside)': False,\n",
       "  'contains(favorite)': False,\n",
       "  'contains(modern)': False,\n",
       "  'contains(l)': False,\n",
       "  'contains(wedding)': False,\n",
       "  'contains(stone)': False,\n",
       "  'contains(trek)': False,\n",
       "  'contains(brought)': False,\n",
       "  'contains(trouble)': False,\n",
       "  'contains(otherwise)': False,\n",
       "  'contains(tim)': False,\n",
       "  'contains(allen)': False,\n",
       "  'contains(bond)': False,\n",
       "  'contains(society)': False,\n",
       "  'contains(liked)': False,\n",
       "  'contains(dumb)': False,\n",
       "  'contains(musical)': False,\n",
       "  'contains(stand)': False,\n",
       "  'contains(political)': False,\n",
       "  'contains(various)': False,\n",
       "  'contains(talented)': False,\n",
       "  'contains(particular)': False,\n",
       "  'contains(west)': False,\n",
       "  'contains(state)': False,\n",
       "  'contains(keeps)': False,\n",
       "  'contains(english)': False,\n",
       "  'contains(silly)': False,\n",
       "  'contains(u)': False,\n",
       "  'contains(situations)': False,\n",
       "  'contains(park)': False,\n",
       "  'contains(teen)': True,\n",
       "  'contains(rating)': True,\n",
       "  'contains(slightly)': False,\n",
       "  'contains(steve)': False,\n",
       "  'contains(truth)': False,\n",
       "  'contains(air)': False,\n",
       "  'contains(element)': False,\n",
       "  'contains(joke)': False,\n",
       "  'contains(spend)': False,\n",
       "  'contains(key)': False,\n",
       "  'contains(biggest)': False,\n",
       "  'contains(members)': False,\n",
       "  'contains(effort)': False,\n",
       "  'contains(government)': False,\n",
       "  'contains(focus)': False,\n",
       "  'contains(eddie)': False,\n",
       "  'contains(soundtrack)': True,\n",
       "  'contains(hands)': False,\n",
       "  'contains(earlier)': False,\n",
       "  'contains(chan)': False,\n",
       "  'contains(purpose)': False,\n",
       "  'contains(today)': False,\n",
       "  'contains(showing)': False,\n",
       "  'contains(memorable)': True,\n",
       "  'contains(six)': True,\n",
       "  'contains(cannot)': False,\n",
       "  'contains(max)': False,\n",
       "  'contains(offers)': False,\n",
       "  'contains(rated)': False,\n",
       "  'contains(mars)': False,\n",
       "  'contains(heavy)': False,\n",
       "  'contains(totally)': False,\n",
       "  'contains(control)': False,\n",
       "  'contains(credit)': False,\n",
       "  'contains(fi)': False,\n",
       "  'contains(woody)': False,\n",
       "  'contains(ideas)': False,\n",
       "  'contains(sci)': False,\n",
       "  'contains(wait)': False,\n",
       "  'contains(sit)': False,\n",
       "  'contains(female)': False,\n",
       "  'contains(ask)': False,\n",
       "  'contains(waste)': False,\n",
       "  'contains(terrible)': False,\n",
       "  'contains(depth)': False,\n",
       "  'contains(simon)': False,\n",
       "  'contains(aspect)': False,\n",
       "  'contains(list)': False,\n",
       "  'contains(mary)': False,\n",
       "  'contains(sister)': False,\n",
       "  'contains(animation)': False,\n",
       "  'contains(entirely)': False,\n",
       "  'contains(fear)': False,\n",
       "  'contains(steven)': False,\n",
       "  'contains(moves)': False,\n",
       "  'contains(actual)': False,\n",
       "  'contains(army)': False,\n",
       "  'contains(british)': False,\n",
       "  'contains(constantly)': False,\n",
       "  'contains(fire)': False,\n",
       "  'contains(convincing)': False,\n",
       "  'contains(setting)': False,\n",
       "  'contains(gave)': False,\n",
       "  'contains(tension)': False,\n",
       "  'contains(street)': False,\n",
       "  'contains(brief)': False,\n",
       "  'contains(ridiculous)': False,\n",
       "  'contains(cinematography)': False,\n",
       "  'contains(typical)': False,\n",
       "  'contains(nick)': False,\n",
       "  'contains(screenwriter)': False,\n",
       "  'contains(ability)': False,\n",
       "  'contains(spent)': False,\n",
       "  'contains(quick)': True,\n",
       "  'contains(violent)': False,\n",
       "  'contains(atmosphere)': False,\n",
       "  'contains(subtle)': False,\n",
       "  'contains(expected)': False,\n",
       "  'contains(fairly)': False,\n",
       "  'contains(seven)': False,\n",
       "  'contains(killing)': False,\n",
       "  'contains(tone)': False,\n",
       "  'contains(master)': False,\n",
       "  'contains(disaster)': False,\n",
       "  'contains(lots)': False,\n",
       "  'contains(thinks)': False,\n",
       "  'contains(song)': False,\n",
       "  'contains(cheap)': False,\n",
       "  'contains(suddenly)': False,\n",
       "  'contains(background)': False,\n",
       "  'contains(club)': False,\n",
       "  'contains(willis)': False,\n",
       "  'contains(whatever)': False,\n",
       "  'contains(highly)': False,\n",
       "  'contains(sees)': False,\n",
       "  'contains(complex)': False,\n",
       "  'contains(greatest)': False,\n",
       "  'contains(impact)': False,\n",
       "  'contains(beauty)': False,\n",
       "  'contains(front)': False,\n",
       "  'contains(humans)': False,\n",
       "  'contains(indeed)': False,\n",
       "  'contains(flat)': False,\n",
       "  'contains(grace)': False,\n",
       "  'contains(wrote)': False,\n",
       "  'contains(amusing)': False,\n",
       "  'contains(ii)': False,\n",
       "  'contains(mike)': False,\n",
       "  'contains(cute)': True,\n",
       "  'contains(dull)': False,\n",
       "  'contains(minor)': False,\n",
       "  'contains(recently)': False,\n",
       "  'contains(hate)': False,\n",
       "  'contains(outside)': False,\n",
       "  'contains(plenty)': False,\n",
       "  'contains(wish)': False,\n",
       "  'contains(godzilla)': False,\n",
       "  'contains(college)': False,\n",
       "  'contains(titanic)': False,\n",
       "  'contains(sounds)': True,\n",
       "  'contains(telling)': True,\n",
       "  'contains(sight)': False,\n",
       "  'contains(double)': False,\n",
       "  'contains(cinematic)': False,\n",
       "  'contains(queen)': False,\n",
       "  'contains(hold)': False,\n",
       "  'contains(meanwhile)': False,\n",
       "  'contains(awful)': True,\n",
       "  'contains(clearly)': False,\n",
       "  'contains(theme)': False,\n",
       "  'contains(hear)': False,\n",
       "  'contains(x)': False,\n",
       "  'contains(amount)': False,\n",
       "  'contains(baby)': False,\n",
       "  'contains(approach)': False,\n",
       "  'contains(dreams)': False,\n",
       "  'contains(shown)': False,\n",
       "  'contains(island)': False,\n",
       "  'contains(reasons)': False,\n",
       "  'contains(charm)': False,\n",
       "  'contains(miss)': False,\n",
       "  'contains(longer)': False,\n",
       "  'contains(common)': False,\n",
       "  'contains(sean)': False,\n",
       "  'contains(carry)': False,\n",
       "  'contains(believable)': False,\n",
       "  'contains(realistic)': False,\n",
       "  'contains(chemistry)': False,\n",
       "  'contains(possibly)': False,\n",
       "  'contains(casting)': False,\n",
       "  'contains(carrey)': False,\n",
       "  'contains(french)': False,\n",
       "  'contains(trailer)': False,\n",
       "  'contains(tough)': False,\n",
       "  'contains(produced)': False,\n",
       "  'contains(imagine)': False,\n",
       "  'contains(choice)': False,\n",
       "  'contains(ride)': False,\n",
       "  'contains(somewhere)': False,\n",
       "  'contains(hot)': False,\n",
       "  'contains(race)': False,\n",
       "  'contains(road)': False,\n",
       "  'contains(leader)': False,\n",
       "  'contains(thin)': False,\n",
       "  'contains(jerry)': False,\n",
       "  'contains(slowly)': False,\n",
       "  'contains(delivers)': False,\n",
       "  'contains(detective)': False,\n",
       "  'contains(brown)': False,\n",
       "  'contains(jackson)': False,\n",
       "  'contains(member)': False,\n",
       "  'contains(provide)': False,\n",
       "  'contains(president)': False,\n",
       "  'contains(puts)': False,\n",
       "  'contains(asks)': False,\n",
       "  'contains(critics)': False,\n",
       "  'contains(appearance)': False,\n",
       "  'contains(famous)': False,\n",
       "  'contains(okay)': False,\n",
       "  'contains(intelligence)': False,\n",
       "  'contains(energy)': False,\n",
       "  'contains(sent)': False,\n",
       "  'contains(spielberg)': False,\n",
       "  'contains(development)': False,\n",
       "  'contains(etc)': False,\n",
       "  'contains(language)': False,\n",
       "  'contains(blue)': False,\n",
       "  'contains(proves)': False,\n",
       "  'contains(vampire)': False,\n",
       "  'contains(seemingly)': False,\n",
       "  'contains(basic)': False,\n",
       "  'contains(caught)': False,\n",
       "  'contains(decide)': False,\n",
       "  'contains(opportunity)': False,\n",
       "  'contains(incredibly)': False,\n",
       "  'contains(images)': False,\n",
       "  'contains(band)': False,\n",
       "  'contains(j)': False,\n",
       "  'contains(writers)': False,\n",
       "  ...},\n",
       " 'neg')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresets[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train_set, test_set and perform classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88\n",
      "Most Informative Features\n",
      "   contains(outstanding) = True              pos : neg    =     10.4 : 1.0\n",
      "        contains(seagal) = True              neg : pos    =      8.7 : 1.0\n",
      "         contains(mulan) = True              pos : neg    =      8.1 : 1.0\n",
      "   contains(wonderfully) = True              pos : neg    =      6.3 : 1.0\n",
      "         contains(damon) = True              pos : neg    =      5.7 : 1.0\n",
      "          contains(lame) = True              neg : pos    =      5.6 : 1.0\n",
      "        contains(wasted) = True              neg : pos    =      5.6 : 1.0\n",
      "         contains(awful) = True              neg : pos    =      5.4 : 1.0\n",
      "         contains(flynt) = True              pos : neg    =      5.1 : 1.0\n",
      "    contains(ridiculous) = True              neg : pos    =      5.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = featuresets[100:], featuresets[:100]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "\n",
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK gives us 88% accuracy, which isn't bad, but our home-made naive algorithm also achieved a respectable 80%.\n",
    "\n",
    "\n",
    "What improvements could we have made? Obviously, we could have used more data, or – in our home-grown model select words that discriminate between good and bad reviews. We could have used n-grams, e.g., to catch \"not bad\" as a postitive sentiment."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
